{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "466d5c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 17:31:42.863863: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-19 17:31:42.967021: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8473] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-19 17:31:43.002124: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1471] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-19 17:31:43.172370: I tensorflow/core/platform/cpu_feature_guard.cc:211] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.17.0\n",
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1763573507.747241     140 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1763573508.170321     140 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1763573508.170355     140 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import project modules\n",
    "from conllu_reader import ConlluReader\n",
    "from algorithm import ArcEager, Transition, Sample\n",
    "from conllu_token import Token\n",
    "from model import ParserMLP\n",
    "\n",
    "# Check for GPU availability (Optional)\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74611103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from dataset.pkl...\n",
      "Dataset loaded successfully!\n",
      "Training Samples: 81182\n",
      "Development Samples: 4978\n",
      "Unique Dependency Labels: 43\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"dataset.pkl\"\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    print(f\"Error: '{dataset_path}' not found. Please run main.py first to generate it.\")\n",
    "else:\n",
    "    print(f\"Loading dataset from {dataset_path}...\")\n",
    "    with open(dataset_path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "        \n",
    "    training_samples = data[\"training_samples\"]\n",
    "    dev_samples = data[\"dev_samples\"]\n",
    "    deprels = data[\"deprels\"]\n",
    "    actions = data[\"actions\"]\n",
    "    \n",
    "    print(\"Dataset loaded successfully!\")\n",
    "    print(f\"Training Samples: {len(training_samples)}\")\n",
    "    print(f\"Development Samples: {len(dev_samples)}\")\n",
    "    print(f\"Unique Dependency Labels: {len(deprels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f786192a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sample 1 ---\n",
      "State Stack: ['ROOT', 'enlisted', '.']\n",
      "State Buffer (first 3): []...\n",
      "Gold Transition: LEFT-ARC-det\n"
     ]
    }
   ],
   "source": [
    "# Inspect the first training sample\n",
    "sample = training_samples[80000]\n",
    "\n",
    "print(f\"--- Sample 1 ---\")\n",
    "# Note: Accessing internal state for visualization\n",
    "print(f\"State Stack: {[t.form for t in sample.state.S]}\")\n",
    "print(f\"State Buffer (first 3): {[t.form for t in sample.state.B[:3]]}...\")\n",
    "print(f\"Gold Transition: {sample.transition}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716d8c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature List: ['.', 'enlisted', '<PAD>', '<PAD>', 'PUNCT', 'VERB', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "# Extract features from the loaded sample\n",
    "feats = sample.state_to_feats(nstack_feats=2, nbuffer_feats=2)\n",
    "\n",
    "print(\"Feature List:\", feats)\n",
    "\n",
    "# Expected output format: \n",
    "# [Stack_Word_1, Stack_Word_0, Buffer_Word_0, Buffer_Word_1, \n",
    "#  Stack_UPOS_1, Stack_UPOS_0, Buffer_UPOS_0, Buffer_UPOS_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f0ce179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Building vocabulary...\n",
      "Vocab built: 1004 words, 16 UPOS tags.\n",
      "Outputs: 4 actions, 43 dependency labels.\n",
      "Vectorizing data...\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " words_input (InputLayer)    [(None, 4)]                  0         []                            \n",
      "                                                                                                  \n",
      " upos_input (InputLayer)     [(None, 4)]                  0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 4, 100)               100400    ['words_input[0][0]']         \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 4, 50)                800       ['upos_input[0][0]']          \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 400)                  0         ['embedding[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 200)                  0         ['embedding_1[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 600)                  0         ['flatten[0][0]',             \n",
      "                                                                     'flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 64)                   38464     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 64)                   0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " action_output (Dense)       (None, 4)                    260       ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " deprel_output (Dense)       (None, 43)                   2795      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 142719 (557.50 KB)\n",
      "Trainable params: 142719 (557.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1763573633.476557     140 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1763573633.476613     140 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1763573633.476623     140 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1763573633.766474     140 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1763573633.766531     140 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-19 17:33:53.766540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1763573633.766577     140 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-19 17:33:53.767146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2816 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 5070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 12.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1763573635.976285     223 service.cc:146] XLA service 0x78ef260c2ab0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1763573635.976319     223 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 5070 Laptop GPU, Compute Capability 12.0\n",
      "2025-11-19 17:33:55.996032: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-11-19 17:33:56.216303: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90701\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "I0000 00:00:1763573636.294220     223 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3/2537 [..............................] - ETA: 3:08 - loss: 3.2448 - action_output_loss: 1.3756 - deprel_output_loss: 3.7384 - action_output_accuracy: 0.3229 - deprel_output_accuracy: 0.1771  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6/2537 [..............................] - ETA: 3:36 - loss: 3.2216 - action_output_loss: 1.3660 - deprel_output_loss: 3.7113 - action_output_accuracy: 0.3177 - deprel_output_accuracy: 0.3177"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  28/2537 [..............................] - ETA: 1:05 - loss: 3.0813 - action_output_loss: 1.3610 - deprel_output_loss: 3.4406 - action_output_accuracy: 0.3170 - deprel_output_accuracy: 0.4308"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  75/2537 [..............................] - ETA: 36s - loss: 2.8146 - action_output_loss: 1.3858 - deprel_output_loss: 2.8576 - action_output_accuracy: 0.2975 - deprel_output_accuracy: 0.4621"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  89/2537 [>.............................] - ETA: 36s - loss: 2.7780 - action_output_loss: 1.3874 - deprel_output_loss: 2.7812 - action_output_accuracy: 0.2949 - deprel_output_accuracy: 0.4645"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 265/2537 [==>...........................] - ETA: 21s - loss: 2.6151 - action_output_loss: 1.3947 - deprel_output_loss: 2.4409 - action_output_accuracy: 0.2834 - deprel_output_accuracy: 0.4771"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 318/2537 [==>...........................] - ETA: 21s - loss: 2.5986 - action_output_loss: 1.3938 - deprel_output_loss: 2.4096 - action_output_accuracy: 0.2839 - deprel_output_accuracy: 0.4792"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 419/2537 [===>..........................] - ETA: 2:59 - loss: 2.5784 - action_output_loss: 1.3912 - deprel_output_loss: 2.3743 - action_output_accuracy: 0.2870 - deprel_output_accuracy: 0.4798"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1217/2537 [=============>................] - ETA: 49s - loss: 2.5212 - action_output_loss: 1.3790 - deprel_output_loss: 2.2843 - action_output_accuracy: 0.2931 - deprel_output_accuracy: 0.4831"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2199/2537 [=========================>....] - ETA: 8s - loss: 2.5002 - action_output_loss: 1.3725 - deprel_output_loss: 2.2552 - action_output_accuracy: 0.2986 - deprel_output_accuracy: 0.4858 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2537/2537 [==============================] - 28s 10ms/step - loss: 2.4963 - action_output_loss: 1.3720 - deprel_output_loss: 2.2487 - action_output_accuracy: 0.2984 - deprel_output_accuracy: 0.4868 - val_loss: 2.4778 - val_action_output_loss: 1.3579 - val_deprel_output_loss: 2.2398 - val_action_output_accuracy: 0.3055 - val_deprel_output_accuracy: 0.4767\n",
      "Epoch 2/3\n",
      "2422/2537 [===========================>..] - ETA: 2s - loss: 2.4629 - action_output_loss: 1.3615 - deprel_output_loss: 2.2027 - action_output_accuracy: 0.3009 - deprel_output_accuracy: 0.4874 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2537/2537 [==============================] - 27s 11ms/step - loss: 2.4632 - action_output_loss: 1.3615 - deprel_output_loss: 2.2034 - action_output_accuracy: 0.3011 - deprel_output_accuracy: 0.4872 - val_loss: 2.4759 - val_action_output_loss: 1.3580 - val_deprel_output_loss: 2.2359 - val_action_output_accuracy: 0.3043 - val_deprel_output_accuracy: 0.4767\n",
      "Epoch 3/3\n",
      "2537/2537 [==============================] - 42s 17ms/step - loss: 2.4514 - action_output_loss: 1.3592 - deprel_output_loss: 2.1845 - action_output_accuracy: 0.3002 - deprel_output_accuracy: 0.4872 - val_loss: 2.4780 - val_action_output_loss: 1.3622 - val_deprel_output_loss: 2.2315 - val_action_output_accuracy: 0.2995 - val_deprel_output_accuracy: 0.4767\n"
     ]
    }
   ],
   "source": [
    "# Initialize Model\n",
    "# You can adjust dimensions and epochs as needed\n",
    "model = ParserMLP(word_emb_dim=100, hidden_dim=64, epochs=3, batch_size=32)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "# The train function handles vocabulary building and vectorization internally\n",
    "model.train(training_samples, dev_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d700001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on sentence:\n",
      "Creative Commons Corporation is not a law firm and does not provide legal services .\n",
      "\n",
      "Parsed Result:\n",
      "ID  FORM            HEAD  DEPREL\n",
      "----------------------------------------\n",
      "1   Creative        _     _\n",
      "2   Commons         _     _\n",
      "3   Corporation     _     _\n",
      "4   is              _     _\n",
      "5   not             _     _\n",
      "6   a               _     _\n",
      "7   law             _     _\n",
      "8   firm            _     _\n",
      "9   and             _     _\n",
      "10  does            11    acl\n",
      "11  not             12    acl\n",
      "12  provide         _     _\n",
      "13  legal           14    acl\n",
      "14  services        15    acl\n",
      "15  .               _     _\n",
      "\n",
      "Unlabeled Attachment Score (UAS): 0.13\n"
     ]
    }
   ],
   "source": [
    "# 1. Load a sentence for testing (e.g., from the dev set)\n",
    "reader = ConlluReader()\n",
    "dev_trees = reader.read_conllu_file(\"en_partut-ud-dev_clean.conllu\", inference=False)\n",
    "dev_trees = reader.remove_non_projective_trees(dev_trees)\n",
    "\n",
    "# Pick a sentence\n",
    "original_tree = dev_trees[0]\n",
    "input_tokens = []\n",
    "\n",
    "# Create a clean version of the tokens (simulating inference mode)\n",
    "for t in original_tree:\n",
    "    new_token = Token(t.id, t.form, t.lemma, t.upos, t.cpos, t.feats, \"_\", \"_\") \n",
    "    input_tokens.append(new_token)\n",
    "\n",
    "# 2. Run the model\n",
    "print(\"Running inference on sentence:\")\n",
    "print(\" \".join([t.form for t in input_tokens if t.id != 0]))\n",
    "\n",
    "# Pass as a list of sentences (even if just one)\n",
    "parsed_sents = model.run([input_tokens])\n",
    "parsed_tree = parsed_sents[0]\n",
    "\n",
    "# 3. Inspect Results\n",
    "print(\"\\nParsed Result:\")\n",
    "print(f\"{'ID':<3} {'FORM':<15} {'HEAD':<5} {'DEPREL'}\")\n",
    "print(\"-\" * 40)\n",
    "for t in parsed_tree:\n",
    "    if t.id == 0: continue\n",
    "    print(f\"{t.id:<3} {t.form:<15} {t.head:<5} {t.dep}\")\n",
    "\n",
    "# 4. Compare with Gold Standard\n",
    "correct_heads = 0\n",
    "total_tokens = 0\n",
    "for pred, gold in zip(parsed_tree, original_tree):\n",
    "    if pred.id == 0: continue\n",
    "    total_tokens += 1\n",
    "    if str(pred.head) == str(gold.head):\n",
    "        correct_heads += 1\n",
    "\n",
    "uas = correct_heads / total_tokens if total_tokens > 0 else 0\n",
    "print(f\"\\nUnlabeled Attachment Score (UAS): {uas:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
