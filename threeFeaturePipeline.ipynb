{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "466d5c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 17:58:38.854627: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-03 17:58:38.882149: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8473] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-03 17:58:38.893761: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1471] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-03 17:58:38.920220: I tensorflow/core/platform/cpu_feature_guard.cc:211] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.17.0\n",
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1764784721.112245    4433 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1764784721.335991    4433 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1764784721.336091    4433 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import project modules\n",
    "from conllu_reader import ConlluReader\n",
    "from algorithm import ArcEager, Transition, Sample\n",
    "from conllu_token import Token\n",
    "from model import ParserMLP\n",
    "\n",
    "# Check for GPU availability (Optional)\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74611103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from dataset.pkl...\n",
      "Dataset loaded successfully!\n",
      "Training Samples: 81182\n",
      "Development Samples: 4978\n",
      "Unique Dependency Labels: 43\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"dataset.pkl\"\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    print(f\"Error: '{dataset_path}' not found. Please run main.py first to generate it.\")\n",
    "else:\n",
    "    print(f\"Loading dataset from {dataset_path}...\")\n",
    "    with open(dataset_path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "        \n",
    "    training_samples = data[\"training_samples\"]\n",
    "    dev_samples = data[\"dev_samples\"]\n",
    "    deprels = data[\"deprels\"]\n",
    "    actions = data[\"actions\"]\n",
    "    \n",
    "    print(\"Dataset loaded successfully!\")\n",
    "    print(f\"Training Samples: {len(training_samples)}\")\n",
    "    print(f\"Development Samples: {len(dev_samples)}\")\n",
    "    print(f\"Unique Dependency Labels: {len(deprels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f786192a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sample 1 ---\n",
      "State Stack: ['ROOT', 'The']\n",
      "State Buffer (first 3): ['revolution', 'in', 'the']...\n",
      "Gold Transition: LEFT-ARC-det\n"
     ]
    }
   ],
   "source": [
    "# Inspect the first training sample\n",
    "sample = training_samples[80000]\n",
    "\n",
    "print(f\"--- Sample 1 ---\")\n",
    "# Note: Accessing internal state for visualization\n",
    "print(f\"State Stack: {[t.form for t in sample.state.S]}\")\n",
    "print(f\"State Buffer (first 3): {[t.form for t in sample.state.B[:3]]}...\")\n",
    "print(f\"Gold Transition: {sample.transition}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "716d8c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature List: ['The', 'ROOT', '<PAD>', 'revolution', 'in', 'the', 'DET', 'ROOT_UPOS', '<PAD>', 'NOUN', 'ADP', 'DET']\n"
     ]
    }
   ],
   "source": [
    "# Extract features from the loaded sample\n",
    "feats = sample.state_to_feats(nstack_feats=3, nbuffer_feats=3)\n",
    "\n",
    "print(\"Feature List:\", feats)\n",
    "\n",
    "# Expected output format: \n",
    "# [Stack_Word_1, Stack_Word_0, Buffer_Word_0, Buffer_Word_1, \n",
    "#  Stack_UPOS_1, Stack_UPOS_0, Buffer_UPOS_0, Buffer_UPOS_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f0ce179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Building vocabulary...\n",
      "Vocab built: 6872 words, 20 UPOS tags.\n",
      "Detected Feature Shape: 4 words, 4 tags.\n",
      "Vectorizing data...\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " words_input (InputLayer)    [(None, 4)]                  0         []                            \n",
      "                                                                                                  \n",
      " upos_input (InputLayer)     [(None, 4)]                  0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 4, 100)               687200    ['words_input[0][0]']         \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 4, 50)                1000      ['upos_input[0][0]']          \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 400)                  0         ['embedding[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 200)                  0         ['embedding_1[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 600)                  0         ['flatten[0][0]',             \n",
      "                                                                     'flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 64)                   38464     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 64)                   0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 32)                   2080      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 32)                   0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " action_output (Dense)       (None, 4)                    132       ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " deprel_output (Dense)       (None, 43)                   1419      ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 730295 (2.79 MB)\n",
      "Trainable params: 730295 (2.79 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1764784723.222091    4433 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1764784723.222138    4433 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1764784723.222148    4433 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1764784723.608958    4433 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1764784723.609022    4433 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-03 17:58:43.609030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1764784723.609067    4433 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-03 17:58:43.609087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2816 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 5070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 12.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1764784725.928467    4509 service.cc:146] XLA service 0x769987a88f30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1764784725.928504    4509 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 5070 Laptop GPU, Compute Capability 12.0\n",
      "2025-12-03 17:58:45.933229: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-12-03 17:58:45.956804: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90701\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "I0000 00:00:1764784726.010203    4514 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2/2537 [..............................] - ETA: 4:16 - loss: 4.2027 - action_output_loss: 1.3798 - deprel_output_loss: 3.7640 - action_output_accuracy: 0.3125 - deprel_output_accuracy: 0.0000e+00   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4/2537 [..............................] - ETA: 5:01 - loss: 4.1973 - action_output_loss: 1.3788 - deprel_output_loss: 3.7579 - action_output_accuracy: 0.3125 - deprel_output_accuracy: 0.0078    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6/2537 [..............................] - ETA: 5:05 - loss: 4.1930 - action_output_loss: 1.3813 - deprel_output_loss: 3.7489 - action_output_accuracy: 0.2812 - deprel_output_accuracy: 0.0729"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10/2537 [..............................] - ETA: 4:07 - loss: 4.1838 - action_output_loss: 1.3786 - deprel_output_loss: 3.7402 - action_output_accuracy: 0.2937 - deprel_output_accuracy: 0.1437"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  12/2537 [..............................] - ETA: 2:19:11 - loss: 4.1755 - action_output_loss: 1.3752 - deprel_output_loss: 3.7338 - action_output_accuracy: 0.3151 - deprel_output_accuracy: 0.1875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 502/2537 [====>.........................] - ETA: 2:48 - loss: 1.9575 - action_output_loss: 0.6962 - deprel_output_loss: 1.6818 - action_output_accuracy: 0.7301 - deprel_output_accuracy: 0.5791 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1197/2537 [=============>................] - ETA: 51s - loss: 1.5115 - action_output_loss: 0.5725 - deprel_output_loss: 1.2520 - action_output_accuracy: 0.7842 - deprel_output_accuracy: 0.6678 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2537/2537 [==============================] - 24s 8ms/step - loss: 1.2184 - action_output_loss: 0.4910 - deprel_output_loss: 0.9699 - action_output_accuracy: 0.8164 - deprel_output_accuracy: 0.7304 - val_loss: 0.8371 - val_action_output_loss: 0.3840 - val_deprel_output_loss: 0.6042 - val_action_output_accuracy: 0.8614 - val_deprel_output_accuracy: 0.8094\n",
      "Epoch 2/3\n",
      "2033/2537 [=======================>......] - ETA: 13s - loss: 0.7243 - action_output_loss: 0.3133 - deprel_output_loss: 0.5479 - action_output_accuracy: 0.8869 - deprel_output_accuracy: 0.8286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2474/2537 [============================>.] - ETA: 1s - loss: 0.7157 - action_output_loss: 0.3103 - deprel_output_loss: 0.5406 - action_output_accuracy: 0.8877 - deprel_output_accuracy: 0.8298"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2537/2537 [==============================] - 26s 10ms/step - loss: 0.7152 - action_output_loss: 0.3102 - deprel_output_loss: 0.5400 - action_output_accuracy: 0.8876 - deprel_output_accuracy: 0.8301 - val_loss: 0.8253 - val_action_output_loss: 0.3946 - val_deprel_output_loss: 0.5743 - val_action_output_accuracy: 0.8640 - val_deprel_output_accuracy: 0.8248\n",
      "Epoch 3/3\n",
      " 953/2537 [==========>...................] - ETA: 1:13 - loss: 0.5552 - action_output_loss: 0.2267 - deprel_output_loss: 0.4380 - action_output_accuracy: 0.9190 - deprel_output_accuracy: 0.8558"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2537/2537 [==============================] - 30s 12ms/step - loss: 0.5634 - action_output_loss: 0.2358 - deprel_output_loss: 0.4368 - action_output_accuracy: 0.9151 - deprel_output_accuracy: 0.8561 - val_loss: 0.8466 - val_action_output_loss: 0.4181 - val_deprel_output_loss: 0.5714 - val_action_output_accuracy: 0.8612 - val_deprel_output_accuracy: 0.8290\n"
     ]
    }
   ],
   "source": [
    "# Initialize Model\n",
    "# You can adjust dimensions and epochs as needed\n",
    "model = ParserMLP(word_emb_dim=100, hidden_dim=64, epochs=3, batch_size=32)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "# The train function handles vocabulary building and vectorization internally\n",
    "model.train(training_samples, dev_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f574405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test set...\n",
      "Loaded 153 sentences for testing.\n"
     ]
    }
   ],
   "source": [
    "from conllu_reader import ConlluReader\n",
    "\n",
    "# Initialize reader if not already done\n",
    "reader = ConlluReader()\n",
    "\n",
    "# Load the test set\n",
    "# We use inference=True to ensure we treat this as unparsed data\n",
    "print(\"Loading test set...\")\n",
    "test_trees = reader.read_conllu_file(\"en_partut-ud-test_clean.conllu\", inference=True)\n",
    "print(f\"Loaded {len(test_trees)} sentences for testing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cf32e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0\tROOT\tROOT\tROOT_UPOS\tROOT_CPOS\tROOT_FEATS\t_\t_\t_\t_,\n",
       " 1\tAny\tany\tDET\tDI\tPronType=Ind\t_\t_\t_\t_,\n",
       " 2\tuse\tuse\tNOUN\tS\tNumber=Sing\t_\t_\t_\t_,\n",
       " 3\tof\tof\tADP\tE\t_\t_\t_\t_\t_,\n",
       " 4\tthe\tthe\tDET\tRD\tDefinite=Def|PronType=Art\t_\t_\t_\t_,\n",
       " 5\twork\twork\tNOUN\tS\tNumber=Sing\t_\t_\t_\t_,\n",
       " 6\tother\tother\tADJ\tA\tDegree=Pos\t_\t_\t_\t_,\n",
       " 7\tthan\tthan\tSCONJ\tCS\t_\t_\t_\t_\t_,\n",
       " 8\tas\tas\tADP\tE\t_\t_\t_\t_\t_,\n",
       " 9\tauthorized\tauthorize\tVERB\tV\tTense=Past|VerbForm=Part\t_\t_\t_\t_,\n",
       " 10\tunder\tunder\tADP\tE\t_\t_\t_\t_\t_,\n",
       " 11\tthis\tthis\tDET\tDD\tNumber=Sing|PronType=Dem\t_\t_\t_\t_,\n",
       " 12\tlicense\tlicense\tNOUN\tS\tNumber=Sing\t_\t_\t_\t_,\n",
       " 13\tor\tor\tCCONJ\tCC\t_\t_\t_\t_\t_,\n",
       " 14\tcopyright\tcopyright\tNOUN\tS\tNumber=Sing\t_\t_\t_\t_,\n",
       " 15\tlaw\tlaw\tNOUN\tS\tNumber=Sing\t_\t_\t_\t_,\n",
       " 16\tis\tbe\tAUX\tVA\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t_\t_\t_\t_,\n",
       " 17\tprohibited\tprohibit\tVERB\tV\tTense=Past|VerbForm=Part\t_\t_\t_\t_,\n",
       " 18\t.\t.\tPUNCT\tFS\t_\t_\t_\t_\t_]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_trees[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "358179ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on the test set...\n",
      "Inference complete.\n"
     ]
    }
   ],
   "source": [
    "# Conduct inference on the test set\n",
    "print(\"Running inference on the test set...\")\n",
    "# The model.run method modifies the trees in-place or returns them\n",
    "# It predicts the HEAD and DEPREL for each token\n",
    "predicted_test_trees = model.run(test_trees)\n",
    "\n",
    "print(\"Inference complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c21e5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving raw predictions to output_three_feature_raw.conllu...\n",
      "File saved.\n"
     ]
    }
   ],
   "source": [
    "output_path = \"output_three_feature_raw.conllu\"\n",
    "\n",
    "print(f\"Saving raw predictions to {output_path}...\")\n",
    "reader.write_conllu_file(output_path, predicted_test_trees)\n",
    "print(\"File saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76e814ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing predictions in output_three_feature_raw.conllu...\n",
      "Post-processing complete. Final predictions saved to output_three_feature_fixed.conllu\n"
     ]
    }
   ],
   "source": [
    "from postprocessor import PostProcessor\n",
    "\n",
    "post = PostProcessor()\n",
    "\n",
    "print(f\"Post-processing predictions in {output_path}...\")\n",
    "\n",
    "fixed_trees = post.postprocess(output_path)\n",
    "\n",
    "final_output_path = \"output_three_feature_fixed.conllu\"\n",
    "reader.write_conllu_file(final_output_path, fixed_trees)\n",
    "\n",
    "print(f\"Post-processing complete. Final predictions saved to {final_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4a03dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric     | Precision |    Recall |  F1 Score | AligndAcc\n",
      "-----------+-----------+-----------+-----------+-----------\n",
      "Tokens     |    100.00 |    100.00 |    100.00 |\n",
      "Sentences  |    100.00 |    100.00 |    100.00 |\n",
      "Words      |    100.00 |    100.00 |    100.00 |\n",
      "UPOS       |    100.00 |    100.00 |    100.00 |    100.00\n",
      "XPOS       |    100.00 |    100.00 |    100.00 |    100.00\n",
      "UFeats     |    100.00 |    100.00 |    100.00 |    100.00\n",
      "AllTags    |    100.00 |    100.00 |    100.00 |    100.00\n",
      "Lemmas     |    100.00 |    100.00 |    100.00 |    100.00\n",
      "UAS        |     76.97 |     76.97 |     76.97 |     76.97\n",
      "LAS        |     65.76 |     65.76 |     65.76 |     65.76\n",
      "CLAS       |     50.11 |     49.58 |     49.84 |     49.58\n",
      "MLAS       |     49.15 |     48.62 |     48.89 |     48.62\n",
      "BLEX       |     50.11 |     49.58 |     49.84 |     49.58\n"
     ]
    }
   ],
   "source": [
    "# Run the evaluation script comparing the Gold Standard (test_clean) against your Fixed Output\n",
    "# -v provides verbose output\n",
    "!python conll18_ud_eval.py en_partut-ud-test_clean.conllu output_three_feature_fixed.conllu -v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
